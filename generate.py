import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from diffusers.utils import load_image
import numpy as np
import cv2
from PIL import Image

# ------------------------------------------------
# ControlNet ë° LoRA ëª¨ë¸ ë¡œë“œ
# ------------------------------------------------
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16
)

# 2000 ìŠ¤í…ê¹Œì§€ í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ ì ìš©
pipe.load_lora_weights("./sd15_lora_minhwa/checkpoint-2000", weight_name="pytorch_lora_weights.safetensors")

# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (ì¼ë°˜ì ìœ¼ë¡œ UniPCMultistepSchedulerë¥¼ ì‚¬ìš©)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_xformers_memory_efficient_attention()
pipe.enable_model_cpu_offload()

# ------------------------------------------------
# Canny ì—£ì§€ ë§µ ìƒì„± í•¨ìˆ˜ (ê°•ë„ ì¡°ì ˆ)
# ------------------------------------------------
def get_canny_image(image_path):
    image = load_image(image_path)
    image = np.array(image)
    
    # Canny ì—£ì§€ ë§µì˜ ê°•ë„ ì¡°ì ˆ (thresholdë¥¼ ë‚®ì¶° ì—£ì§€ë¥¼ ì•½í•˜ê²Œ)
    low_threshold = 50
    high_threshold = 100
    
    image = cv2.Canny(image, low_threshold, high_threshold)
    image = image[:, :, None]
    image = np.concatenate([image, image, image], axis=2)
    canny_image = Image.fromarray(image)
    return canny_image

# ì´ë¯¸ì§€ ìƒì„± íŒŒë¼ë¯¸í„° ë° ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

source_image_path = "./inputs/img1.jpg"
base_image = get_canny_image(source_image_path)

# í”„ë¡¬í”„íŠ¸ ì„¤ì •
prompt = "<minhwastyle> painting, oriental ink painting, watercolor, vibrant colors, subtle brush strokes, harmony, a bird on a branch, detailed background"
negative_prompt = "japanese style, chinese style, western painting, oil painting, impressionist, very dark, very bright, saturated colors, photography, bad art, blurry, ugly, duplicate"

# ì´ë¯¸ì§€ ìƒì„±
print("ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...ğŸ¥")
generated_image = pipe(
    prompt,
    image=base_image,
    negative_prompt=negative_prompt,
    num_inference_steps=20,
    guidance_scale=7.5,
    controlnet_conditioning_scale=0.8
).images[0]

# ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥
generated_image.save("./outputs/generated_minhwa_image.png")
print("\nì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ. 'generated_minhwa_image.png' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.ğŸ")